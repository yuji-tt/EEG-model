{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coQMlJO9S5xt"
      },
      "source": [
        "# Deep Learning \u57fa\u790e\u8b1b\u5ea7\u3000\u6700\u7d42\u8ab2\u984c: \u8133\u6ce2\u5206\u985e\n",
        "\n",
        "## \u6982\u8981\n",
        "\u88ab\u9a13\u8005\u304c\u753b\u50cf\u3092\u898b\u3066\u3044\u308b\u3068\u304d\u306e\u8133\u6ce2\u304b\u3089\uff0c\u305d\u306e\u753b\u50cf\u304c\u3069\u306e\u30ab\u30c6\u30b4\u30ea\u306b\u5c5e\u3059\u308b\u304b\u3092\u5206\u985e\u3059\u308b\u30bf\u30b9\u30af\uff0e\n",
        "- \u30b5\u30f3\u30d7\u30eb\u6570: \u8a13\u7df4 118,800 \u30b5\u30f3\u30d7\u30eb\uff0c\u691c\u8a3c 59,400 \u30b5\u30f3\u30d7\u30eb\uff0c\u30c6\u30b9\u30c8 59,400 \u30b5\u30f3\u30d7\u30eb\n",
        "- \u30af\u30e9\u30b9\u6570: 5\n",
        "- \u5165\u529b: \u8133\u6ce2\u30c7\u30fc\u30bf\uff08\u30c1\u30e3\u30f3\u30cd\u30eb\u6570 x \u7cfb\u5217\u9577\uff09\n",
        "- \u51fa\u529b: \u5bfe\u5fdc\u3059\u308b\u753b\u50cf\u306e\u30af\u30e9\u30b9\n",
        "- \u8a55\u4fa1\u6307\u6a19: Top-1 accuracy\n",
        "\n",
        "### \u5143\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8 ([Gifford2022 EEG dataset](https://osf.io/3jk45/)) \u3068\u306e\u9055\u3044\n",
        "\n",
        "- \u672c\u30b3\u30f3\u30da\u3067\u306f\u96e3\u6613\u5ea6\u8abf\u6574\u306e\u76ee\u7684\u3067\u5143\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306b\u3044\u304f\u3064\u304b\u306e\u6539\u5909\u3092\u52a0\u3048\u3066\u3044\u307e\u3059\uff0e\n",
        "\n",
        "1. \u8a13\u7df4\u30bb\u30c3\u30c8\u306e\u307f\u306e\u4f7f\u7528\n",
        "  - \u5143\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u306f\u8a13\u7df4\u30c7\u30fc\u30bf\u306b\u5b58\u5728\u3057\u306a\u304b\u3063\u305f\u30af\u30e9\u30b9\u306e\u753b\u50cf\u3092\u898b\u3066\u3044\u308b\u3068\u304d\u306e\u8133\u6ce2\u306b\u304a\u3044\u3066\u30c6\u30b9\u30c8\u304c\u884c\u308f\u308c\u307e\u3059\u304c\uff0c\u3053\u308c\u306f\u96e3\u6613\u5ea6\u304c\u975e\u5e38\u306b\u9ad8\u304f\u306a\u308a\u307e\u3059\uff0e\n",
        "  - \u672c\u30b3\u30f3\u30da\u3067\u306f\u5143\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u8a13\u7df4\u30bb\u30c3\u30c8\u3092\u518d\u5206\u5272\u3057\uff0c\u8a13\u7df4\u6642\u306b\u5b58\u5728\u3057\u305f\u753b\u50cf\u306b\u5bfe\u5fdc\u3059\u308b\u5225\u306e\u8133\u6ce2\u306b\u304a\u3044\u3066\u691c\u8a3c\u30fb\u30c6\u30b9\u30c8\u3092\u884c\u3044\u307e\u3059\uff0e\n",
        "\n",
        "2. \u30af\u30e9\u30b9\u6570\u306e\u6e1b\u5c11\n",
        "  - \u5143\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\uff08\u306e\u8a13\u7df4\u30bb\u30c3\u30c8\uff09\u3067\u306f16,540\u679a\u306e\u753b\u50cf\u306b\u5bfe\u3057\uff0c1,654\u306e\u30af\u30e9\u30b9\u304c\u5b58\u5728\u3057\u307e\u3059\uff0e\n",
        "    - e.g. `aardvark`, `alligator`, `almond`, ...\n",
        "  - \u672c\u30b3\u30f3\u30da\u3067\u306f1,654\u306e\u30af\u30e9\u30b9\u3092\uff0c`animal`, `food`, `clothing`, `tool`, `vehicle`\u306e5\u3064\u306b\u307e\u3068\u3081\u3066\u3044\u307e\u3059\uff0e\n",
        "    - e.g. `aardvark -> animal`, `alligator -> animal`, `almond -> food`, ...\n",
        "\n",
        "### \u8003\u3048\u3089\u308c\u308b\u5de5\u592b\u306e\u4f8b\n",
        "\n",
        "- \u97f3\u58f0\u30e2\u30c7\u30eb\u306e\u5c0e\u5165\n",
        "  - \u8133\u6ce2\u3068\u540c\u3058\u6ce2\u3067\u3042\u308b\u97f3\u58f0\u3092\u6271\u3046\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u3092\u7528\u3044\u308b\u3053\u3068\u304c\u6709\u52b9\u3067\u3042\u308b\u3068\u77e5\u3089\u308c\u3066\u3044\u307e\u3059\uff0e\n",
        "  - \u4f8b\uff09Conformer [[Gulati+ 2020](https://arxiv.org/abs/2005.08100)]\n",
        "- \u753b\u50cf\u30c7\u30fc\u30bf\u3092\u7528\u3044\u305f\u4e8b\u524d\u5b66\u7fd2\n",
        "  - \u672c\u30b3\u30f3\u30da\u306e\u30bf\u30b9\u30af\u306f\u8133\u6ce2\u306e\u30af\u30e9\u30b9\u5206\u985e\u3067\u3059\u304c\uff0c\u914d\u5e03\u3057\u3066\u3042\u308b\u753b\u50cf\u30c7\u30fc\u30bf\u3092\u8133\u6ce2\u30a8\u30f3\u30b3\u30fc\u30c0\u306e\u4e8b\u524d\u5b66\u7fd2\u306b\u7528\u3044\u308b\u3053\u3068\u3092\u8a31\u53ef\u3057\u307e\u3059\uff0e\n",
        "  - \u4f8b\uff09CLIP [Radford+ 2021]\n",
        "  - \u753b\u50cf\u3092\u7528\u3044\u308b\u5834\u5408\u306f[\u3053\u3061\u3089](https://osf.io/download/3v527/)\u304b\u3089\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u3066\u304f\u3060\u3055\u3044\uff0e\n",
        "- \u904e\u5b66\u7fd2\u3092\u9632\u3050\u6b63\u5247\u5316\u3084\u30c9\u30ed\u30c3\u30d7\u30a2\u30a6\u30c8\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIejJol4XuJO"
      },
      "source": [
        "## \u4fee\u4e86\u8981\u4ef6\u3092\u6e80\u305f\u3059\u6761\u4ef6\n",
        "- \u30d9\u30fc\u30b9\u30e9\u30a4\u30f3\u30e2\u30c7\u30eb\u306ebest test accuracy\u306f38.7%\u3068\u306a\u308a\u307e\u3059\uff0e**\u3053\u308c\u3092\u8d85\u3048\u305f\u63d0\u51fa\u306e\u307f\uff0c\u4fee\u4e86\u8981\u4ef6\u3068\u3057\u3066\u8a8d\u3081\u307e\u3059**\uff0e\n",
        "- \u30d9\u30fc\u30b9\u30e9\u30a4\u30f3\u304b\u3089\u6539\u5584\u3092\u52a0\u3048\u308b\u3053\u3068\u3067\uff0c55%\u307e\u3067\u306f\u6027\u80fd\u5411\u4e0a\u3059\u308b\u3053\u3068\u3092\u904b\u55b6\u3067\u78ba\u8a8d\u3057\u3066\u3044\u307e\u3059\uff0e\u3053\u3061\u3089\u3092 1 \u3064\u306e\u6307\u6a19\u3068\u3057\u3066\u53d6\u308a\u7d44\u3093\u3067\u307f\u3066\u304f\u3060\u3055\u3044\uff0e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvF82AJ4YRoI"
      },
      "source": [
        "## \u6ce8\u610f\u70b9\n",
        "- \u5b66\u7fd2\u3059\u308b\u30e2\u30c7\u30eb\u306b\u3064\u3044\u3066\u5236\u9650\u306f\u3042\u308a\u307e\u305b\u3093\u304c\uff0c\u5fc5\u305a\u8a13\u7df4\u30c7\u30fc\u30bf\u3067\u5b66\u7fd2\u3057\u305f\u30e2\u30c7\u30eb\u3067\u4e88\u6e2c\u3057\u3066\u304f\u3060\u3055\u3044\uff0e\n",
        "    - \u4e8b\u524d\u5b66\u7fd2\u6e08\u307f\u30e2\u30c7\u30eb\u3092\u5229\u7528\u3057\u3066\uff0c\u8a13\u7df4\u30c7\u30fc\u30bf\u3092 fine-tuning \u3057\u3066\u3082\u69cb\u3044\u307e\u305b\u3093\uff0e\n",
        "    - \u57cb\u3081\u8fbc\u307f\u62bd\u51fa\u30e2\u30c7\u30eb\u306a\u3069\uff0c\u30e2\u30c7\u30eb\u306e\u4e00\u90e8\u3092\u8a13\u7df4\u3057\u306a\u3044\u30b1\u30fc\u30b9\u306f\u69cb\u3044\u307e\u305b\u3093\uff0e\n",
        "    - \u5b66\u7fd2\u3092\u4e00\u5207\u305b\u305a\u306b\uff0cChatGPT \u306a\u3069\u306e\u57fa\u76e4\u30e2\u30c7\u30eb\u3092\u5229\u7528\u3059\u308b\u3053\u3068\u306f\u7981\u6b62\u3068\u3057\u307e\u3059\uff0e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGqk3Pi-Qx2i"
      },
      "source": [
        "## 1.\u6e96\u5099"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
            "Collecting ipywidgets\n",
            "  Downloading ipywidgets-8.1.7-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (0.1.3)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (8.14.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (5.9.0)\n",
            "Collecting widgetsnbextension~=4.0.14 (from ipywidgets)\n",
            "  Downloading widgetsnbextension-4.0.14-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting jupyterlab_widgets~=3.0.15 (from ipywidgets)\n",
            "  Downloading jupyterlab_widgets-3.0.15-py3-none-any.whl (216 kB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m216.6/216.6 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.18.2)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (3.0.39)\n",
            "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (2.15.1)\n",
            "Requirement already satisfied: stack-data in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.6)\n",
            "Requirement already satisfied: executing>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.2.0)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
            "Requirement already satisfied: pure-eval in /usr/local/lib/python3.10/dist-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
            "Installing collected packages: widgetsnbextension, jupyterlab_widgets, ipywidgets\n",
            "Successfully installed ipywidgets-8.1.7 jupyterlab_widgets-3.0.15 widgetsnbextension-4.0.14\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# omnicampus \u5b9f\u884c\u7528\n",
        "!pip install ipywidgets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pip install \"timm>=0.9.2\" \"torch>=2.0,<2.1\" \"torchvision>=0.15,<0.16\"\n",
        "# pip install optuna\n",
        "# pip install tsaug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nUHy4caOQK-r"
      },
      "outputs": [],
      "source": [
        "# \u30e9\u30a4\u30d6\u30e9\u30ea\u306e\u30a4\u30f3\u30dd\u30fc\u30c8\u3068\u30b7\u30fc\u30c9\u56fa\u5b9a\n",
        "import os, sys\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from einops.layers.torch import Rearrange\n",
        "from einops import repeat\n",
        "from glob import glob\n",
        "from termcolor import cprint\n",
        "from tqdm.notebook import tqdm\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingLR\n",
        "from einops.layers.torch import Rearrange\n",
        "from einops import rearrange, repeat\n",
        "from timm.layers import DropPath\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import optuna\n",
        "from tsaug import TimeWarp, AddNoise, Reverse, Dropout as TsaugDropout\n",
        "\n",
        "\n",
        "SEED = 0\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3hq0lx0SdY7g"
      },
      "outputs": [],
      "source": [
        "class SubjectNormalizer:\n",
        "    def __init__(self):\n",
        "        self.stats = {}\n",
        "\n",
        "    def fit(self, eegs, subject_idxs):\n",
        "        subject_idxs = torch.tensor(subject_idxs)  \n",
        "        for subj in torch.unique(subject_idxs):\n",
        "            mask = subject_idxs == subj\n",
        "            data = torch.tensor(eegs[mask])  \n",
        "            mean = data.mean(dim=(0, 2), keepdim=True)\n",
        "            std = data.std(dim=(0, 2), keepdim=True) + 1e-6\n",
        "            self.stats[int(subj)] = (mean, std)\n",
        "\n",
        "    def transform(self, eegs, subject_idxs):\n",
        "        subject_idxs = torch.tensor(subject_idxs)  \n",
        "        eegs = torch.tensor(eegs, dtype=torch.float32)  \n",
        "        normed = torch.zeros_like(eegs)\n",
        "        for i, subj in enumerate(subject_idxs):\n",
        "            mean, std = self.stats[int(subj)]\n",
        "            normed[i] = (eegs[i] - mean) / std\n",
        "        return normed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "DATA_DIR   = \"./data/\"\n",
        "DEVICE     = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "BATCH_SIZE = 256\n",
        "EPOCHS     = 30\n",
        "TRIALS     = 15\n",
        "TTA_LOOPS  = 3\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "AUG = (\n",
        "    TimeWarp(n_speed_change=5, max_speed_ratio=2.0) @ 0.5\n",
        "  + AddNoise(scale=0.02) @ 0.5\n",
        "  + Reverse() @ 0.3\n",
        "  + TsaugDropout(p=0.1, size=10) @ 0.5\n",
        ")\n",
        "def tsaugment(x: torch.Tensor) -> torch.Tensor:\n",
        "    x_np = x.permute(1,0).unsqueeze(0).cpu().numpy()\n",
        "    aug = AUG.augment(x_np).squeeze(0)\n",
        "    return torch.from_numpy(aug).permute(1,0)\n",
        "\n",
        "class EEGDataset(Dataset):\n",
        "    def __init__(self, X, y=None, subj=None, augment=False):\n",
        "        if isinstance(X, torch.Tensor):\n",
        "            self.X = X.clone().detach().float()\n",
        "        else:\n",
        "            self.X = torch.tensor(X, dtype=torch.float32)\n",
        "\n",
        "        self.y = None if y is None else torch.tensor(y, dtype=torch.long)\n",
        "        self.subj = None if subj is None else torch.tensor(subj - 1, dtype=torch.long)\n",
        "        self.augment = augment\n",
        "\n",
        "    def __len__(self): return len(self.X)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        x = self.X[i]\n",
        "        if self.augment:\n",
        "            x = tsaugment(x)\n",
        "        if self.y is None:\n",
        "            return x, self.subj[i]\n",
        "        return x, self.y[i], self.subj[i]\n",
        "\n",
        "def get_loaders():\n",
        "    def load(split):\n",
        "        X = np.load(os.path.join(DATA_DIR, f\"{split}/eeg.npy\"))\n",
        "        subj = np.load(os.path.join(DATA_DIR, f\"{split}/subject_idxs.npy\"))\n",
        "        y = None\n",
        "        if split != 'test':\n",
        "            y = np.load(os.path.join(DATA_DIR, f\"{split}/labels.npy\"))\n",
        "        return X, y, subj\n",
        "\n",
        "    X_tr, y_tr, s_tr = load('train')\n",
        "    X_va, y_va, s_va = load('val')\n",
        "    X_te, _,    s_te = load('test')\n",
        "\n",
        "    norm = SubjectNormalizer(); norm.fit(X_tr, s_tr)\n",
        "    X_tr = norm.transform(X_tr, s_tr)\n",
        "    X_va = norm.transform(X_va, s_va)\n",
        "    X_te = norm.transform(X_te, s_te)\n",
        "\n",
        "    tr_dl = DataLoader(EEGDataset(X_tr, y_tr, s_tr, augment=True),  BATCH_SIZE, shuffle=True)\n",
        "    va_dl = DataLoader(EEGDataset(X_va, y_va, s_va),               BATCH_SIZE*2)\n",
        "    te_dl = DataLoader(EEGDataset(X_te,     None, s_te),           BATCH_SIZE*2)\n",
        "    return tr_dl, va_dl, te_dl, norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2HhAzFNRQdgH"
      },
      "outputs": [],
      "source": [
        "class ChannelSEAttention(nn.Module):\n",
        "    def __init__(self, num_channels, reduction=16):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(num_channels, num_channels // reduction)\n",
        "        self.fc2 = nn.Linear(num_channels // reduction, num_channels)\n",
        "    def forward(self, x):  \n",
        "        weights = x.mean(dim=2)             \n",
        "        weights = F.relu(self.fc1(weights))\n",
        "        weights = torch.sigmoid(self.fc2(weights)) \n",
        "        return x * weights.unsqueeze(-1)\n",
        "\n",
        "class SubjectSpatialFilter(nn.Module):\n",
        "    def __init__(self, num_subjects, num_channels):\n",
        "        super().__init__()\n",
        "        weight = torch.stack([torch.eye(num_channels) for _ in range(num_subjects)])\n",
        "        self.register_parameter(\"weight\", nn.Parameter(weight))\n",
        "    def forward(self, x, subj_idx):\n",
        "        W = self.weight[subj_idx]\n",
        "        return torch.bmm(W, x)\n",
        "\n",
        "\n",
        "class MultiScaleConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.branch1 = nn.Conv1d(in_channels, out_channels, kernel_size=5, padding=2)\n",
        "        self.branch2 = nn.Conv1d(in_channels, out_channels, kernel_size=15, padding=7)\n",
        "        self.branch3 = nn.Conv1d(in_channels, out_channels, kernel_size=31, padding=15)\n",
        "        self.bn = nn.BatchNorm1d(out_channels * 3)\n",
        "        self.act = nn.GELU()\n",
        "    def forward(self, x):  \n",
        "        x1 = self.branch1(x)\n",
        "        x2 = self.branch2(x)\n",
        "        x3 = self.branch3(x)\n",
        "        out = torch.cat([x1, x2, x3], dim=1)  \n",
        "        return self.act(self.bn(out))\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, emb_dim, num_heads, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = emb_dim // num_heads\n",
        "        self.qkv = nn.Linear(emb_dim, emb_dim * 3)\n",
        "        self.att_drop = nn.Dropout(dropout)\n",
        "        self.proj = nn.Linear(emb_dim, emb_dim)\n",
        "        self.proj_drop = nn.Dropout(dropout)\n",
        "    def forward(self, x):  # [B, T, C]\n",
        "        B, T, C = x.shape\n",
        "        qkv = self.qkv(x).reshape(B, T, 3, self.num_heads, self.head_dim).permute(2, 0, 3, 1, 4)\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
        "        att = (q @ k.transpose(-2, -1)) * (1.0 / (self.head_dim ** 0.5))\n",
        "        att = F.softmax(att, dim=-1)\n",
        "        att = self.att_drop(att)\n",
        "        x = (att @ v).transpose(1, 2).reshape(B, T, C)\n",
        "        x = self.proj(x)\n",
        "        return self.proj_drop(x)\n",
        "\n",
        "class ConformerBlock(nn.Module):\n",
        "    def __init__(self, emb_dim, num_heads, kernel_size=31, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.ffn1 = nn.Sequential(\n",
        "            nn.LayerNorm(emb_dim),\n",
        "            nn.Linear(emb_dim, emb_dim * 4),\n",
        "            nn.SiLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(emb_dim * 4, emb_dim),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "        self.attn = nn.Sequential(\n",
        "            nn.LayerNorm(emb_dim),\n",
        "            MultiHeadAttention(emb_dim, num_heads, dropout)\n",
        "        )\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.LayerNorm(emb_dim),\n",
        "            Rearrange('b t c -> b c t'),\n",
        "            nn.Conv1d(emb_dim, 2 * emb_dim, kernel_size, padding=kernel_size // 2, groups=emb_dim),\n",
        "            nn.GLU(dim=1),\n",
        "            nn.BatchNorm1d(emb_dim),\n",
        "            nn.SiLU(),\n",
        "            nn.Conv1d(emb_dim, emb_dim, 1),\n",
        "            Rearrange('b c t -> b t c'),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "        self.ffn2 = nn.Sequential(\n",
        "            nn.LayerNorm(emb_dim),\n",
        "            nn.Linear(emb_dim, emb_dim * 4),\n",
        "            nn.SiLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(emb_dim * 4, emb_dim),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.ffn1(x)\n",
        "        x = x + self.attn(x)\n",
        "        x = x + self.conv(x)\n",
        "        x = x + self.ffn2(x)\n",
        "        return x\n",
        "\n",
        "class EEGEnhancedModel(nn.Module):\n",
        "    def __init__(self, num_classes, num_subjects, num_channels, seq_len, emb_dim=256, depth=6):\n",
        "        super().__init__()\n",
        "        self.subject_filter = SubjectSpatialFilter(num_subjects, num_channels)\n",
        "        self.channel_att = ChannelSEAttention(num_channels)\n",
        "        self.temporal = MultiScaleConvBlock(num_channels, emb_dim // 3)\n",
        "        self.project = nn.Conv1d(emb_dim, emb_dim, 1)\n",
        "        self.pos_emb = nn.Parameter(torch.randn(1, seq_len, emb_dim))\n",
        "        self.blocks = nn.Sequential(*[ConformerBlock(emb_dim, num_heads=8) for _ in range(depth)])\n",
        "        self.cls_token = nn.Parameter(torch.randn(1, 1, emb_dim))\n",
        "        self.norm = nn.LayerNorm(emb_dim)\n",
        "        self.head = nn.Linear(emb_dim, num_classes)\n",
        "\n",
        "    def forward(self, x, subj_idx):  \n",
        "        x = self.subject_filter(x, subj_idx)\n",
        "        x = self.channel_att(x)\n",
        "        x = self.temporal(x)\n",
        "        x = self.project(x)\n",
        "        x = rearrange(x, 'b c t -> b t c')\n",
        "        b, t, e = x.shape\n",
        "        cls = self.cls_token.expand(b, -1, -1)\n",
        "        x = torch.cat([cls, x + self.pos_emb[:, :t]], dim=1)\n",
        "        x = self.blocks(x)\n",
        "        x = self.norm(x[:, 0])\n",
        "        return self.head(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.cuda.amp import GradScaler, autocast\n",
        "optuna.logging.set_verbosity(optuna.logging.INFO)\n",
        "\n",
        "def optuna_search():\n",
        "    tr_dl, va_dl, _, norm = get_loaders()\n",
        "    scaler = GradScaler()\n",
        "\n",
        "    def objective(trial):\n",
        "        emb   = trial.suggest_categorical(\"emb_dim\", [312, 384, 480])\n",
        "        depth = trial.suggest_int(\"depth\", 5, 10)\n",
        "        lr    = trial.suggest_float(\"lr\", 3e-4, 1e-3, log=True)\n",
        "        sm    = trial.suggest_float(\"smooth\", 0.0, 0.15)\n",
        "\n",
        "        print(f\"Trying: emb={emb}, depth={depth}, lr={lr:.5f}, smooth={sm:.3f}\")\n",
        "\n",
        "        model = EEGEnhancedModel(5, 10, 17, 100, emb, depth).to(DEVICE)\n",
        "        optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
        "        scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
        "            optimizer, max_lr=lr, epochs=3, steps_per_epoch=len(tr_dl)\n",
        "        )\n",
        "        criterion = nn.CrossEntropyLoss(label_smoothing=sm)\n",
        "\n",
        "        for epoch in range(3):\n",
        "            model.train()\n",
        "            print(f\"  Epoch {epoch+1}/3\")\n",
        "            for i, (x, y, s) in enumerate(tr_dl):\n",
        "                x, y, s = x.to(DEVICE), y.to(DEVICE), s.to(DEVICE)\n",
        "                optimizer.zero_grad()\n",
        "                with autocast():\n",
        "                    loss = criterion(model(x, s), y)\n",
        "                scaler.scale(loss).backward()\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "                scheduler.step()\n",
        "                if i == 0:\n",
        "                    print(f\"    Batch 1: loss={loss.item():.4f}\")\n",
        "\n",
        "            # validation\n",
        "            model.eval(); correct, total = 0, 0\n",
        "            with torch.no_grad():\n",
        "                for x, y, s in va_dl:\n",
        "                    x, y, s = x.to(DEVICE), y.to(DEVICE), s.to(DEVICE)\n",
        "                    with autocast():\n",
        "                        pred = model(x, s).argmax(1)\n",
        "                    correct += (pred == y).sum().item()\n",
        "                    total += y.size(0)\n",
        "            val_acc = correct / total\n",
        "            print(f\"    Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "            trial.report(val_acc, epoch)\n",
        "            if trial.should_prune():\n",
        "                print(\"    Trial pruned.\")\n",
        "                raise optuna.TrialPruned()\n",
        "\n",
        "        return val_acc\n",
        "\n",
        "    study = optuna.create_study(\n",
        "        direction=\"maximize\",\n",
        "        pruner=optuna.pruners.MedianPruner(n_warmup_steps=1)\n",
        "    )\n",
        "    study.optimize(objective, n_trials=TRIALS)\n",
        "    print(\"Best params:\", study.best_params)\n",
        "    return study.best_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=10, verbose=True):\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, val_acc):\n",
        "        score = val_acc\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "        elif score <= self.best_score:\n",
        "            self.counter += 1\n",
        "            if self.verbose:\n",
        "                print(f\"  \u23f8 No improvement. {self.counter}/{self.patience} patience used.\")\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            if self.verbose and self.counter > 0:\n",
        "                print(\"Accuracy improved, resetting patience.\")\n",
        "            self.best_score = score\n",
        "            self.counter = 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "o5ftIHtyPrSu"
      },
      "outputs": [],
      "source": [
        "from itertools import islice\n",
        "import pickle\n",
        "\n",
        "def train_full_and_save(params, n_splits: int = 5):\n",
        "    scaler = GradScaler()\n",
        "    X_all = np.concatenate([\n",
        "        np.load(DATA_DIR + \"train/eeg.npy\"),\n",
        "        np.load(DATA_DIR + \"val/eeg.npy\")\n",
        "    ])\n",
        "    y_all = np.concatenate([\n",
        "        np.load(DATA_DIR + \"train/labels.npy\"),\n",
        "        np.load(DATA_DIR + \"val/labels.npy\")\n",
        "    ])\n",
        "    s_all = np.concatenate([\n",
        "        np.load(DATA_DIR + \"train/subject_idxs.npy\"),\n",
        "        np.load(DATA_DIR + \"val/subject_idxs.npy\")\n",
        "    ])\n",
        "\n",
        "    kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "    for fold, (tr_idx, va_idx) in islice(enumerate(kfold.split(X_all, y_all)), 3):\n",
        "        print(f\"\\n=== Fold {fold} / 2 ===\")\n",
        "\n",
        "        model_path = f\"model_fold{fold}.pth\"\n",
        "        ckpt_path  = f\"checkpoint_fold{fold}.pt\"\n",
        "\n",
        "        if os.path.exists(model_path):\n",
        "            print(f\"Fold {fold} already trained. Skipping.\")\n",
        "            continue\n",
        "            \n",
        "        X_tr, y_tr, s_tr = X_all[tr_idx], y_all[tr_idx], s_all[tr_idx]\n",
        "        X_va, y_va, s_va = X_all[va_idx], y_all[va_idx], s_all[va_idx]\n",
        "\n",
        "        start_epoch = 0\n",
        "        if os.path.exists(ckpt_path):\n",
        "            print(f\"Resuming from checkpoint: {ckpt_path}\")\n",
        "            ckpt = torch.load(ckpt_path)\n",
        "            model = EEGEnhancedModel(5, 10, 17, 100, params['emb_dim'], params['depth']).to(DEVICE)\n",
        "            model.load_state_dict(ckpt['model_state_dict'])\n",
        "            opt = torch.optim.AdamW(model.parameters(), lr=params['lr'])\n",
        "            opt.load_state_dict(ckpt['optimizer_state_dict'])\n",
        "            sch = torch.optim.lr_scheduler.OneCycleLR(opt, max_lr=params['lr'], epochs=EPOCHS, steps_per_epoch=len(X_tr)//BATCH_SIZE)\n",
        "            sch.load_state_dict(ckpt['scheduler_state_dict'])\n",
        "            es = ckpt['early_stopping']\n",
        "            norm = ckpt['norm']\n",
        "            start_epoch = ckpt['epoch'] + 1\n",
        "        else:\n",
        "            model = EEGEnhancedModel(5, 10, 17, 100, params['emb_dim'], params['depth']).to(DEVICE)\n",
        "            opt = torch.optim.AdamW(model.parameters(), lr=params['lr'])\n",
        "            sch = torch.optim.lr_scheduler.OneCycleLR(opt, max_lr=params['lr'], epochs=EPOCHS, steps_per_epoch=len(X_tr)//BATCH_SIZE)\n",
        "            crit = nn.CrossEntropyLoss(label_smoothing=params['smooth'])\n",
        "            es = EarlyStopping(patience=3)\n",
        "            norm = SubjectNormalizer()\n",
        "            norm.fit(X_tr, s_tr)\n",
        "\n",
        "        X_tr = norm.transform(X_tr, s_tr)\n",
        "        X_va = norm.transform(X_va, s_va)\n",
        "\n",
        "        tr_dl = DataLoader(EEGDataset(X_tr, y_tr, s_tr, augment=True), BATCH_SIZE, shuffle=True)\n",
        "        va_dl = DataLoader(EEGDataset(X_va, y_va, s_va), BATCH_SIZE*2)\n",
        "\n",
        "        crit = nn.CrossEntropyLoss(label_smoothing=params['smooth'])\n",
        "\n",
        "        for epoch in range(start_epoch, EPOCHS):\n",
        "            model.train()\n",
        "            for x, y, sb in tr_dl:\n",
        "                x, y, sb = x.to(DEVICE), y.to(DEVICE), sb.to(DEVICE)\n",
        "                opt.zero_grad()\n",
        "                with autocast():\n",
        "                    loss = crit(model(x, sb), y)\n",
        "                scaler.scale(loss).backward()\n",
        "                scaler.step(opt)\n",
        "                scaler.update()\n",
        "                sch.step()\n",
        "\n",
        "            model.eval(); correct = total = 0\n",
        "            with torch.no_grad():\n",
        "                for x, y, sb in va_dl:\n",
        "                    x, y, sb = x.to(DEVICE), y.to(DEVICE), sb.to(DEVICE)\n",
        "                    with autocast():\n",
        "                        pred = model(x, sb).argmax(1)\n",
        "                    correct += (pred == y).sum().item()\n",
        "                    total += y.size(0)\n",
        "            val_acc = correct / total\n",
        "            print(f\"Fold {fold}  Epoch {epoch+1}  ValAcc {val_acc:.4f}\")\n",
        "\n",
        "            if es.best_score is None or val_acc > es.best_score:\n",
        "                torch.save(model.state_dict(), model_path)\n",
        "                print(\" New best model saved.\")\n",
        "\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': opt.state_dict(),\n",
        "                'scheduler_state_dict': sch.state_dict(),\n",
        "                'early_stopping': es,\n",
        "                'norm': norm,\n",
        "            }, ckpt_path)\n",
        "\n",
        "            es(val_acc)\n",
        "            if es.early_stop:\n",
        "                print(\" EarlyStopping.\")\n",
        "                break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-18 06:16:48,673] A new study created in memory with name: no-name-ed64548d-8d6e-4cfd-bec5-a761457a7bce\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trying: emb=384, depth=10, lr=0.00070, smooth=0.031\n",
            "  Epoch 1/3\n",
            "    Batch 1: loss=1.6960\n",
            "    Val Acc: 0.4008\n",
            "  Epoch 2/3\n",
            "    Batch 1: loss=1.5079\n",
            "    Val Acc: 0.4742\n",
            "  Epoch 3/3\n",
            "    Batch 1: loss=1.3836\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-18 06:44:08,429] Trial 0 finished with value: 0.4857575757575758 and parameters: {'emb_dim': 384, 'depth': 10, 'lr': 0.0006958322562772423, 'smooth': 0.03104644135977158}. Best is trial 0 with value: 0.4857575757575758.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Val Acc: 0.4858\n",
            "Trying: emb=312, depth=5, lr=0.00043, smooth=0.094\n",
            "  Epoch 1/3\n",
            "    Batch 1: loss=1.5869\n",
            "    Val Acc: 0.3880\n",
            "  Epoch 2/3\n",
            "    Batch 1: loss=1.4819\n",
            "    Val Acc: 0.4614\n",
            "  Epoch 3/3\n",
            "    Batch 1: loss=1.4174\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-18 07:02:04,118] Trial 1 finished with value: 0.47734006734006734 and parameters: {'emb_dim': 312, 'depth': 5, 'lr': 0.00042937377820675114, 'smooth': 0.09448069968796559}. Best is trial 0 with value: 0.4857575757575758.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Val Acc: 0.4773\n",
            "Trying: emb=384, depth=5, lr=0.00050, smooth=0.139\n",
            "  Epoch 1/3\n",
            "    Batch 1: loss=1.6207\n",
            "    Val Acc: 0.3958\n",
            "  Epoch 2/3\n",
            "    Batch 1: loss=1.4976\n",
            "    Val Acc: 0.4577\n",
            "  Epoch 3/3\n",
            "    Batch 1: loss=1.3909\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-18 07:21:25,521] Trial 2 finished with value: 0.48175084175084176 and parameters: {'emb_dim': 384, 'depth': 5, 'lr': 0.0005011371630416184, 'smooth': 0.13934316911686168}. Best is trial 0 with value: 0.4857575757575758.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Val Acc: 0.4818\n",
            "Trying: emb=384, depth=6, lr=0.00050, smooth=0.122\n",
            "  Epoch 1/3\n",
            "    Batch 1: loss=1.7988\n",
            "    Val Acc: 0.4033\n",
            "  Epoch 2/3\n",
            "    Batch 1: loss=1.5455\n",
            "    Val Acc: 0.4539\n",
            "  Epoch 3/3\n",
            "    Batch 1: loss=1.4357\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-18 07:42:23,380] Trial 3 finished with value: 0.480976430976431 and parameters: {'emb_dim': 384, 'depth': 6, 'lr': 0.0004961663935629247, 'smooth': 0.12232456139678108}. Best is trial 0 with value: 0.4857575757575758.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Val Acc: 0.4810\n",
            "Trying: emb=384, depth=8, lr=0.00035, smooth=0.095\n",
            "  Epoch 1/3\n",
            "    Batch 1: loss=1.9041\n",
            "    Val Acc: 0.3872\n",
            "  Epoch 2/3\n",
            "    Batch 1: loss=1.5044\n",
            "    Val Acc: 0.4513\n",
            "  Epoch 3/3\n",
            "    Batch 1: loss=1.4275\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-18 08:06:35,996] Trial 4 finished with value: 0.47496632996633 and parameters: {'emb_dim': 384, 'depth': 8, 'lr': 0.0003545453772150599, 'smooth': 0.09529970552183809}. Best is trial 0 with value: 0.4857575757575758.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Val Acc: 0.4750\n",
            "Trying: emb=384, depth=9, lr=0.00072, smooth=0.089\n",
            "  Epoch 1/3\n",
            "    Batch 1: loss=1.7601\n",
            "    Val Acc: 0.4072\n",
            "  Epoch 2/3\n",
            "    Batch 1: loss=1.5056\n",
            "    Val Acc: 0.4591\n",
            "  Epoch 3/3\n",
            "    Batch 1: loss=1.4547\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-18 08:32:23,057] Trial 5 pruned. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Val Acc: 0.4773\n",
            "    Trial pruned.\n",
            "Trying: emb=480, depth=6, lr=0.00039, smooth=0.008\n",
            "  Epoch 1/3\n",
            "    Batch 1: loss=1.8071\n",
            "    Val Acc: 0.2925\n",
            "  Epoch 2/3\n",
            "    Batch 1: loss=1.6032\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-18 08:47:54,900] Trial 6 pruned. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Val Acc: 0.4493\n",
            "    Trial pruned.\n",
            "Trying: emb=480, depth=8, lr=0.00072, smooth=0.021\n",
            "  Epoch 1/3\n",
            "    Batch 1: loss=1.5438\n",
            "    Val Acc: 0.3873\n",
            "  Epoch 2/3\n",
            "    Batch 1: loss=1.4591\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-18 09:06:07,174] Trial 7 pruned. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Val Acc: 0.4354\n",
            "    Trial pruned.\n",
            "Trying: emb=312, depth=7, lr=0.00063, smooth=0.060\n",
            "  Epoch 1/3\n",
            "    Batch 1: loss=1.7402\n",
            "    Val Acc: 0.4181\n",
            "  Epoch 2/3\n",
            "    Batch 1: loss=1.4377\n",
            "    Val Acc: 0.4793\n",
            "  Epoch 3/3\n",
            "    Batch 1: loss=1.4170\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-18 09:26:39,738] Trial 8 finished with value: 0.4881144781144781 and parameters: {'emb_dim': 312, 'depth': 7, 'lr': 0.0006324137498211563, 'smooth': 0.05974557224801802}. Best is trial 8 with value: 0.4881144781144781.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Val Acc: 0.4881\n",
            "Trying: emb=480, depth=10, lr=0.00055, smooth=0.077\n",
            "  Epoch 1/3\n",
            "    Batch 1: loss=1.6213\n",
            "    Val Acc: 0.3493\n",
            "  Epoch 2/3\n",
            "    Batch 1: loss=1.5823\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-18 09:47:13,191] Trial 9 pruned. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Val Acc: 0.4568\n",
            "    Trial pruned.\n",
            "Trying: emb=312, depth=7, lr=0.00096, smooth=0.051\n",
            "  Epoch 1/3\n",
            "    Batch 1: loss=1.5742\n",
            "    Val Acc: 0.3945\n",
            "  Epoch 2/3\n",
            "    Batch 1: loss=1.4640\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-18 10:00:39,843] Trial 10 pruned. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Val Acc: 0.4489\n",
            "    Trial pruned.\n",
            "Trying: emb=312, depth=10, lr=0.00069, smooth=0.044\n",
            "  Epoch 1/3\n",
            "    Batch 1: loss=1.7942\n",
            "    Val Acc: 0.3888\n",
            "  Epoch 2/3\n",
            "    Batch 1: loss=1.4405\n",
            "    Val Acc: 0.4633\n",
            "  Epoch 3/3\n",
            "    Batch 1: loss=1.3762\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-18 10:24:45,095] Trial 11 pruned. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Val Acc: 0.4811\n",
            "    Trial pruned.\n",
            "Trying: emb=312, depth=7, lr=0.00093, smooth=0.037\n",
            "  Epoch 1/3\n",
            "    Batch 1: loss=1.6889\n",
            "    Val Acc: 0.4149\n",
            "  Epoch 2/3\n",
            "    Batch 1: loss=1.4738\n",
            "    Val Acc: 0.4619\n",
            "  Epoch 3/3\n",
            "    Batch 1: loss=1.3862\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-18 10:44:52,342] Trial 12 finished with value: 0.4874242424242424 and parameters: {'emb_dim': 312, 'depth': 7, 'lr': 0.0009250288919173885, 'smooth': 0.0372371512336716}. Best is trial 8 with value: 0.4881144781144781.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Val Acc: 0.4874\n",
            "Trying: emb=312, depth=7, lr=0.00095, smooth=0.056\n",
            "  Epoch 1/3\n",
            "    Batch 1: loss=1.8189\n",
            "    Val Acc: 0.3968\n",
            "  Epoch 2/3\n",
            "    Batch 1: loss=1.4981\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-18 10:58:19,070] Trial 13 pruned. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Val Acc: 0.4508\n",
            "    Trial pruned.\n",
            "Trying: emb=312, depth=6, lr=0.00030, smooth=0.000\n",
            "  Epoch 1/3\n",
            "    Batch 1: loss=1.9150\n",
            "    Val Acc: 0.4037\n",
            "  Epoch 2/3\n",
            "    Batch 1: loss=1.4214\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-18 11:10:55,141] Trial 14 pruned. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Val Acc: 0.4502\n",
            "    Trial pruned.\n",
            "Best params: {'emb_dim': 312, 'depth': 7, 'lr': 0.0006324137498211563, 'smooth': 0.05974557224801802}\n",
            "\n",
            "=== Fold 0 / 5 ===\n",
            "Fold 0  Epoch 1  ValAcc 0.3872\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'EarlyStopping' object has no attribute 'best_acc'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m      2\u001b[0m     best \u001b[38;5;241m=\u001b[39m optuna_search()\n\u001b[0;32m----> 3\u001b[0m     model,norm \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_full_and_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     predict_tta(model, norm)\n",
            "Cell \u001b[0;32mIn[7], line 63\u001b[0m, in \u001b[0;36mtrain_full_and_save\u001b[0;34m(params, n_splits)\u001b[0m\n\u001b[1;32m     60\u001b[0m val_acc \u001b[38;5;241m=\u001b[39m correct \u001b[38;5;241m/\u001b[39m total\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m  Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m  ValAcc \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val_acc \u001b[38;5;241m>\u001b[39m \u001b[43mes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_acc\u001b[49m:\n\u001b[1;32m     64\u001b[0m     torch\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mstate_dict(), best_path)\n\u001b[1;32m     65\u001b[0m es\u001b[38;5;241m.\u001b[39mstep(val_acc)\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'EarlyStopping' object has no attribute 'best_acc'"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "    best = optuna_search()\n",
        "    model,norm = train_full_and_save(best)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Fold 0 / 2 ===\n",
            "Fold 0  Epoch 1  ValAcc 0.3872\n",
            " New best model saved.\n",
            "Fold 0  Epoch 2  ValAcc 0.4012\n",
            " New best model saved.\n",
            "Fold 0  Epoch 3  ValAcc 0.4554\n",
            " New best model saved.\n",
            "Fold 0  Epoch 4  ValAcc 0.4745\n",
            " New best model saved.\n",
            "Fold 0  Epoch 5  ValAcc 0.4824\n",
            " New best model saved.\n",
            "Fold 0  Epoch 6  ValAcc 0.4929\n",
            " New best model saved.\n",
            "Fold 0  Epoch 7  ValAcc 0.4798\n",
            "  \u23f8 No improvement. 1/3 patience used.\n",
            "Fold 0  Epoch 8  ValAcc 0.5078\n",
            " New best model saved.\n",
            "Accuracy improved, resetting patience.\n",
            "Fold 0  Epoch 9  ValAcc 0.5019\n",
            "  \u23f8 No improvement. 1/3 patience used.\n",
            "Fold 0  Epoch 10  ValAcc 0.5149\n",
            " New best model saved.\n",
            "Accuracy improved, resetting patience.\n",
            "Fold 0  Epoch 11  ValAcc 0.5138\n",
            "  \u23f8 No improvement. 1/3 patience used.\n",
            "Fold 0  Epoch 12  ValAcc 0.5165\n",
            " New best model saved.\n",
            "Accuracy improved, resetting patience.\n",
            "Fold 0  Epoch 13  ValAcc 0.5215\n",
            " New best model saved.\n",
            "Fold 0  Epoch 14  ValAcc 0.5258\n",
            " New best model saved.\n",
            "Fold 0  Epoch 15  ValAcc 0.5264\n",
            " New best model saved.\n",
            "Fold 0  Epoch 16  ValAcc 0.5304\n",
            " New best model saved.\n",
            "Fold 0  Epoch 17  ValAcc 0.5325\n",
            " New best model saved.\n",
            "Fold 0  Epoch 18  ValAcc 0.5306\n",
            "  \u23f8 No improvement. 1/3 patience used.\n",
            "Fold 0  Epoch 19  ValAcc 0.5308\n",
            "  \u23f8 No improvement. 2/3 patience used.\n",
            "Fold 0  Epoch 20  ValAcc 0.5196\n",
            "  \u23f8 No improvement. 3/3 patience used.\n",
            " EarlyStopping.\n",
            "\n",
            "=== Fold 1 / 2 ===\n",
            "Fold 1  Epoch 1  ValAcc 0.3872\n",
            " New best model saved.\n",
            "Fold 1  Epoch 2  ValAcc 0.3894\n",
            " New best model saved.\n",
            "Fold 1  Epoch 3  ValAcc 0.4604\n",
            " New best model saved.\n",
            "Fold 1  Epoch 4  ValAcc 0.4744\n",
            " New best model saved.\n",
            "Fold 1  Epoch 5  ValAcc 0.4780\n",
            " New best model saved.\n",
            "Fold 1  Epoch 6  ValAcc 0.4922\n",
            " New best model saved.\n",
            "Fold 1  Epoch 7  ValAcc 0.5015\n",
            " New best model saved.\n",
            "Fold 1  Epoch 8  ValAcc 0.5004\n",
            "  \u23f8 No improvement. 1/3 patience used.\n",
            "Fold 1  Epoch 9  ValAcc 0.5035\n",
            " New best model saved.\n",
            "Accuracy improved, resetting patience.\n",
            "Fold 1  Epoch 10  ValAcc 0.5071\n",
            " New best model saved.\n",
            "Fold 1  Epoch 11  ValAcc 0.5164\n",
            " New best model saved.\n",
            "Fold 1  Epoch 12  ValAcc 0.5113\n",
            "  \u23f8 No improvement. 1/3 patience used.\n",
            "Fold 1  Epoch 13  ValAcc 0.5153\n",
            "  \u23f8 No improvement. 2/3 patience used.\n",
            "Fold 1  Epoch 14  ValAcc 0.5248\n",
            " New best model saved.\n",
            "Accuracy improved, resetting patience.\n",
            "Fold 1  Epoch 15  ValAcc 0.5224\n",
            "  \u23f8 No improvement. 1/3 patience used.\n",
            "Fold 1  Epoch 16  ValAcc 0.5246\n",
            "  \u23f8 No improvement. 2/3 patience used.\n",
            "Fold 1  Epoch 17  ValAcc 0.5267\n",
            " New best model saved.\n",
            "Accuracy improved, resetting patience.\n",
            "Fold 1  Epoch 18  ValAcc 0.5272\n",
            " New best model saved.\n",
            "Fold 1  Epoch 19  ValAcc 0.5248\n",
            "  \u23f8 No improvement. 1/3 patience used.\n",
            "Fold 1  Epoch 20  ValAcc 0.5269\n",
            "  \u23f8 No improvement. 2/3 patience used.\n",
            "Fold 1  Epoch 21  ValAcc 0.5289\n",
            " New best model saved.\n",
            "Accuracy improved, resetting patience.\n",
            "Fold 1  Epoch 22  ValAcc 0.5264\n",
            "  \u23f8 No improvement. 1/3 patience used.\n",
            "Fold 1  Epoch 23  ValAcc 0.5261\n",
            "  \u23f8 No improvement. 2/3 patience used.\n",
            "Fold 1  Epoch 24  ValAcc 0.5236\n",
            "  \u23f8 No improvement. 3/3 patience used.\n",
            " EarlyStopping.\n",
            "\n",
            "=== Fold 2 / 2 ===\n",
            "Fold 2  Epoch 1  ValAcc 0.3872\n",
            " New best model saved.\n",
            "Fold 2  Epoch 2  ValAcc 0.3952\n",
            " New best model saved.\n",
            "Fold 2  Epoch 3  ValAcc 0.4560\n",
            " New best model saved.\n",
            "Fold 2  Epoch 4  ValAcc 0.4731\n",
            " New best model saved.\n",
            "Fold 2  Epoch 5  ValAcc 0.4875\n",
            " New best model saved.\n",
            "Fold 2  Epoch 6  ValAcc 0.4959\n",
            " New best model saved.\n",
            "Fold 2  Epoch 7  ValAcc 0.4987\n",
            " New best model saved.\n",
            "Fold 2  Epoch 8  ValAcc 0.5060\n",
            " New best model saved.\n",
            "Fold 2  Epoch 9  ValAcc 0.5031\n",
            "  \u23f8 No improvement. 1/3 patience used.\n",
            "Fold 2  Epoch 10  ValAcc 0.5118\n",
            " New best model saved.\n",
            "Accuracy improved, resetting patience.\n",
            "Fold 2  Epoch 11  ValAcc 0.5147\n",
            " New best model saved.\n",
            "Fold 2  Epoch 12  ValAcc 0.5173\n",
            " New best model saved.\n",
            "Fold 2  Epoch 13  ValAcc 0.5073\n",
            "  \u23f8 No improvement. 1/3 patience used.\n",
            "Fold 2  Epoch 14  ValAcc 0.5160\n",
            "  \u23f8 No improvement. 2/3 patience used.\n",
            "Fold 2  Epoch 15  ValAcc 0.5197\n",
            " New best model saved.\n",
            "Accuracy improved, resetting patience.\n",
            "Fold 2  Epoch 16  ValAcc 0.5242\n",
            " New best model saved.\n",
            "Fold 2  Epoch 17  ValAcc 0.5253\n",
            " New best model saved.\n",
            "Fold 2  Epoch 18  ValAcc 0.5262\n",
            " New best model saved.\n",
            "Fold 2  Epoch 19  ValAcc 0.5250\n",
            "  \u23f8 No improvement. 1/3 patience used.\n",
            "Fold 2  Epoch 20  ValAcc 0.5250\n",
            "  \u23f8 No improvement. 2/3 patience used.\n",
            "Fold 2  Epoch 21  ValAcc 0.5250\n",
            "  \u23f8 No improvement. 3/3 patience used.\n",
            " EarlyStopping.\n"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "    best = {\n",
        "    'emb_dim': 312,\n",
        "    'depth': 7,\n",
        "    'lr': 0.0006324137498211563,\n",
        "    'smooth': 0.05974557224801802\n",
        "    }\n",
        "    \n",
        "    train_full_and_save(best)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "def tsaugment2(x: torch.Tensor) -> torch.Tensor:\n",
        "    x_np = x.permute(0, 2, 1).cpu().numpy()\n",
        "    \n",
        "    aug_np = AUG.augment(x_np)  \n",
        "\n",
        "    aug = torch.from_numpy(aug_np).permute(0, 2, 1).to(x.device)\n",
        "    return aug\n",
        "\n",
        "def predict_ensemble_tta(folds=[0, 1, 2]):\n",
        "    X_test = np.load(DATA_DIR + \"test/eeg.npy\")\n",
        "    s_test = np.load(DATA_DIR + \"test/subject_idxs.npy\")\n",
        "    raw_dataset = EEGDataset(X_test, None, s_test)  \n",
        "    raw_loader = DataLoader(raw_dataset, batch_size=BATCH_SIZE*2)\n",
        "\n",
        "    all_logits = []\n",
        "\n",
        "    for fold in folds:\n",
        "        model_path = f\"model_fold{fold}.pth\"\n",
        "        norm_path  = f\"norm_fold{fold}.pkl\"\n",
        "        if not (os.path.exists(model_path) and os.path.exists(norm_path)):\n",
        "            print(f\"Skip Fold {fold}: model or norm not found.\")\n",
        "            continue\n",
        "\n",
        "        model = EEGEnhancedModel(5, 10, 17, 100, emb_dim=best['emb_dim'], depth=best['depth']).to(DEVICE)\n",
        "        model.load_state_dict(torch.load(model_path))\n",
        "        model.eval()\n",
        "\n",
        "        with open(norm_path, \"rb\") as f:\n",
        "            norm = pickle.load(f)\n",
        "\n",
        "        X_norm = norm.transform(X_test.copy(), s_test)\n",
        "        test_ds = EEGDataset(X_norm, None, s_test)\n",
        "        test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE*2)\n",
        "\n",
        "        fold_logits = []\n",
        "        with torch.no_grad():\n",
        "            for X, subj in tqdm(test_loader, desc=f\"TTA Fold {fold}\"):\n",
        "                X, subj = X.to(DEVICE), subj.to(DEVICE)\n",
        "                logit_accum = torch.zeros((X.size(0), 5), device=DEVICE)\n",
        "                for _ in range(TTA_LOOPS):\n",
        "                    Xa = tsaugment2(X)\n",
        "                    logit_accum += model(Xa, subj)\n",
        "                logits = logit_accum / TTA_LOOPS\n",
        "                fold_logits.append(logits.cpu())\n",
        "\n",
        "        all_logits.append(torch.cat(fold_logits, dim=0))\n",
        "\n",
        "    avg_logits = torch.stack(all_logits).mean(dim=0).numpy()\n",
        "    np.save(\"submission\", avg_logits)\n",
        "    print(f\"Saved: submission.npy (shape={avg_logits.shape})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "norm_fold0.pkl saved successfully.\n"
          ]
        }
      ],
      "source": [
        "fold = 0 \n",
        "\n",
        "ckpt = torch.load(f\"checkpoint_fold{fold}.pt\")\n",
        "\n",
        "# norm \u3092\u53d6\u5f97\u3057\u3066\u4fdd\u5b58\n",
        "norm = ckpt['norm']\n",
        "with open(f\"norm_fold{fold}.pkl\", \"wb\") as f:\n",
        "    pickle.dump(norm, f)\n",
        "\n",
        "print(f\"norm_fold{fold}.pkl saved successfully.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "norm_fold1.pkl saved successfully.\n"
          ]
        }
      ],
      "source": [
        "fold = 1\n",
        "\n",
        "ckpt = torch.load(f\"checkpoint_fold{fold}.pt\")\n",
        "\n",
        "# norm \u3092\u53d6\u5f97\u3057\u3066\u4fdd\u5b58\n",
        "norm = ckpt['norm']\n",
        "with open(f\"norm_fold{fold}.pkl\", \"wb\") as f:\n",
        "    pickle.dump(norm, f)\n",
        "\n",
        "print(f\"norm_fold{fold}.pkl saved successfully.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b10898b2973d4c1fa4dd0ac89af5d1f7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "TTA Fold 0:   0%|          | 0/117 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1b219af1302f4ad4af360f9f307d8278",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "TTA Fold 1:   0%|          | 0/117 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved: submission.npy (shape=(59400, 5))\n"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "    predict_ensemble_tta(folds=[0, 1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSuRjyoDihdK"
      },
      "source": [
        "## \u63d0\u51fa\u65b9\u6cd5\n",
        "\n",
        "\u4ee5\u4e0b\u306e3\u70b9\u3092zip\u5316\u3057\uff0cOmnicampus\u306e\u300c\u6700\u7d42\u8ab2\u984c (EEG)\u300d\u304b\u3089\u63d0\u51fa\u3057\u3066\u304f\u3060\u3055\u3044\uff0e\n",
        "\n",
        "- `submission.npy`\n",
        "- `model_last.pt`\u3084`model_best.pt`\u306a\u3069\uff0c\u30c6\u30b9\u30c8\u306b\u4f7f\u7528\u3057\u305f\u91cd\u307f\uff08\u62e1\u5f35\u5b50\u306f`.pt`\u306e\u307f\uff09\n",
        "- \u672cColab Notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "mlrJFVFQ33nF"
      },
      "outputs": [],
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "model_path1 = \"norm_fold0.pkl\"\n",
        "model_path2 = \"norm_fold1.pkl\"\n",
        "notebook_path = \"optuna.ipynb\"\n",
        "\n",
        "with ZipFile(\"submission.zip\", \"w\") as zf:\n",
        "    zf.write(\"submission.npy\")\n",
        "    zf.write(model_path1)\n",
        "    zf.write(model_path2)\n",
        "    zf.write(notebook_path)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyMds57nNMooFyIP3NK7bW7T",
      "gpuType": "T4",
      "mount_file_id": "1TeDBTtv4TCWmt3U82HdMwZlcZHz4x5mt",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}